# Theoretical Technical Report on Heracles V1 to V4

## Table of Contents

- [Theoretical Technical Report on Heracles V1 to V4](#theoretical-technical-report-on-heracles-v1-to-v4)
  - [Table of Contents](#table-of-contents)
  - [Introduction](#introduction)
  - [System Architecture](#system-architecture)
  - [Hardware Components and Specifications](#hardware-components-and-specifications)
  - [Dataset Description](#dataset-description)
  - [Software and Control Systems](#software-and-control-systems)
    - [Reinforcement Learning Framework](#reinforcement-learning-framework)
    - [Simulation Environments](#simulation-environments)
    - [Micro-Operation Integration](#micro-operation-integration)
  - [Integration with Advanced Features](#integration-with-advanced-features)
  - [Version-Specific Details](#version-specific-details)
    - [V1](#v1)
    - [V2](#v2)
    - [V3](#v3)
    - [V4](#v4)
  - [Implementation Considerations](#implementation-considerations)
  - [Conclusion and Future Work](#conclusion-and-future-work)
  - [Document Data](#document-data)


## Introduction

The Heracles system represents a theoretical humanoid robotics platform engineered to advance capabilities in motion control, precise manipulation, adaptive locomotion, and integrated creative content generation within simulated environments. This platform synthesizes concepts from foundational robotics designs, micro-operation strategies for motion segmentation, dance learning and creation mechanisms, Lie group-based perceptual frameworks for geometric transformation modeling, and natural language-driven generative systems for text, dance, and music outputs. The system facilitates applications such as dance instruction, object handling, responsive movement in varied scenarios, and user-guided content creation in creative domains. It progresses through four versions: V1 emphasizing basic rigid structure actuation, V2 incorporating segmented flexibility in the waist, V3 extending segmentation to all joints with rotational enhancements, and V4 optimizing for cost efficiency through streamlined single-motor configurations.

Due to the halt in physical development as of October 2025, the Heracles system focuses on theoretical principles, conceptual interconnections, and simulation-based evaluations using tools like Gazebo for dynamics, MuJoCo for rapid computations, or ROS for integrated control. This report examines the system's architecture, hardware specifications, software mechanisms, operational principles, and version-specific attributes, including features, advantages, disadvantages, defects, improvements, and prospective developments.

## System Architecture

The Heracles system utilizes a modular, hierarchical architecture to support scalable processing and control for humanoid motions and creative generations. The architecture comprises a hardware layer for physical actuation and sensing, a software layer for computation and decision-making, data flow pathways for information exchange, and APIs for module communication.

The hardware layer includes NEMA 17 stepper motors (model 57BYG250B, rated at 1.2 N·m torque and 3A current) as primary actuators, L298N drivers for motor control, spur gears (8-tooth input and 20-tooth output) in V1 and V2 for torque amplification, tendon-driven mechanisms in V3 and V4 for flexible joint operation, a computing unit (Raspberry Pi 5 with 8GB RAM for V1 to V3, Arduino Nano with 64KB SRAM for V4), and a power supply (24V lithium-polymer battery with 5000mAh capacity for V1 to V3, 12V lithium-ion battery with 3000mAh capacity for V4). In V3 and V4, high-strength Dyneema tendons route through aluminum pulleys, with stainless steel springs (spring constant k=50 N/m) in V4 providing return forces. Sensing integrates simulated strain gauges (resolution 0.01 N) for tension feedback and high-resolution cameras (1080p at 60fps) for pose detection.

The software layer consists of a Python-based framework using PyTorch for reinforcement learning models, micro-operation decomposition algorithms to break motions into discrete units, natural language processing via BERT-derived models for user query interpretation, Lie group-based perceptual models for geometric transformations, and generative algorithms for dance and music creation. The reinforcement learning employs Proximal Policy Optimization to optimize actions, while generative components use transformer architectures for sequence generation in text, motion, and audio.

Data flow begins with inputs from the S.O.F.I.A. dataset (motion records, video frames) or user queries, processed through perceptual models for pose estimation and geometric alignment, then routed to reinforcement learning for motion control or generative modules for content creation. Outputs include motor control signals via GPIO or generated media files. Feedback loops use sensor data to refine models in real-time.

APIs, implemented as JSON protocols, connect modules: for example, the pose detection API sends joint coordinates to the reinforcement learning module, which outputs tension adjustments for tendons.

In actual operation, the software coordinates by parsing user inputs (e.g., "Generate a dance routine for upbeat music"), extracting parameters via named entity recognition, invoking generative models to produce motion sequences aligned with music features (e.g., BPM via mel-frequency cepstral coefficients analysis), and simulating hardware responses in tools like Gazebo, where joint torques are applied step-by-step.

## Hardware Components and Specifications

The hardware components vary by version but share core elements for actuation, control, and power. Below is a detailed breakdown of each component's type and function, followed by a table listing costs based on theoretical bulk estimates as of October 2025.

- **Stepper Motors**: NEMA 17 model 57BYG250B, bipolar configuration with 200 steps per revolution, used for precise angular control in joints. In operation, they receive pulse-width modulation signals from drivers to achieve 1.8° steps, enabling micro-movements.
- **Motor Drivers**: L298N dual H-bridge modules, capable of handling 3A per channel, configured to drive 2 motors per driver in V1 to V3 and 4 in V4 for efficiency. They convert GPIO logic signals into high-current outputs for motor coils.
- **Gears (V1 and V2)**: Steel spur gears with 8-tooth input pinion and 20-tooth output gear, module 1.0, providing a 2.5:1 ratio for torque amplification. They mesh to transfer rotational force without slippage.
- **Tendons and Pulleys (V3 and V4)**: Dyneema braided cables (diameter 1mm, tensile strength 500N) routed over aluminum grooved pulleys (diameter 20mm), allowing force transmission across segments.
- **Springs (V4)**: Helical compression springs made of stainless steel, with wire diameter 1mm and spring constant 50 N/m, providing passive return forces proportional to displacement.
- **Computing Unit**: Raspberry Pi 5 (quad-core ARM Cortex-A76 processor at 2.4GHz) for V1 to V3 handles complex RL computations; Arduino Nano (ATmega328P microcontroller at 16MHz) for V4 manages simplified control loops.
- **Battery**: 24V lithium-polymer pack (6 cells, 5000mAh, discharge rate 20C) for V1 to V3 supplies up to 120W; 12V lithium-ion pack (3 cells, 3000mAh, discharge rate 15C) for V4 provides 45W.
- **Sensors**: Simulated strain gauges (piezoresistive type, sensitivity 2mV/V) for tension, and CMOS cameras (resolution 1920x1080, focal length 3.6mm) for visual input.

| Component | Type/Specification | V1 Cost (USD) | V2 Cost (USD) | V3 Cost (USD) | V4 Cost (USD) |
|-----------|--------------------|---------------|---------------|---------------|---------------|
| Stepper Motors | NEMA 17 57BYG250B, 1.2 N·m, 3A | 230 (46 units) | 760 (152 units) | 705 (141 units) | 355 (71 units) |
| Motor Drivers | L298N dual H-bridge, 3A/channel | 230 (23 units) | 760 (76 units) | 710 (71 units) | 72 (18 units) |
| Gears | Steel spur, 8/20 teeth, module 1.0 | 64 | 64 | N/A | N/A |
| Tendons and Pulleys | Dyneema cable 1mm, aluminum pulleys 20mm | N/A | N/A | 100 | 7 |
| Springs | Stainless steel helical, k=50 N/m | N/A | N/A | N/A | Included in tendons cost |
| Computing Unit | Raspberry Pi 5 8GB RAM / Arduino Nano ATmega328P | 90 | 90 | 90 | 20 |
| Battery | 24V LiPo 5000mAh 20C / 12V Li-ion 3000mAh 15C | 75 | 75 | 100 | 30 |
| Sensors (Strain Gauges) | Piezoresistive, 2mV/V sensitivity | Included in drivers | Included in drivers | Included in drivers | Included in drivers |
| Sensors (Cameras) | CMOS 1080p 60fps, 3.6mm lens | Included in computing | Included in computing | Included in computing | Included in computing |
| **Total** | - | 689 | 1749 | 1705 | 454 |

In operation, hardware components interact seamlessly: for example, in V4, the Arduino Nano processes RL outputs to send PWM signals to L298N drivers, which activate motors to tension Dyneema tendons against springs, achieving joint flexion with feedback from strain gauges adjusting the next cycle.

## Dataset Description

The S.O.F.I.A. dataset captures motion records including thigh Y-axis revolutions, brake status (binary 0/1), X-axis rotations, and RPM, structured in outdoor and indoor folders with .mp4 videos and JSON files for per-frame data. In operation, software loads JSON for RL training, aligning video frames with motion parameters to simulate adaptive behaviors in varied environments.

## Software and Control Systems

### Reinforcement Learning Framework

The framework operates through an eight-step process where software and hardware coordinate closely. Initially, the simulated GPIO interface initializes connections. Python libraries load, and the control program interprets RL actions into pulses (1.8° per step) or tensions. The Markov Decision Process uses states like angles and tensions, actions such as adjustments, and rewards balancing accuracy, efficiency, and stability. PPO training occurs in Gazebo or MuJoCo, with sensor feedback enabling closed-loop corrections. Real-time control dispatches commands, and optimization refines parameters like learning rates. For V4, the Arduino Nano executes simplified loops, receiving PyTorch-exported models via serial communication for on-device inference.

### Simulation Environments

Gazebo simulates physics with ROS for V1 to V3, while MuJoCo handles V4's faster iterations. Software loads models, runs scenarios, and logs metrics like error rates.

### Micro-Operation Integration

Motions segment into units (e.g., 1.8° steps or 0.1N tension changes), with software generating sequences based on task goals, executing them sequentially while monitoring feedback for adjustments.

## Integration with Advanced Features

Dance practice processes videos to map poses to motor commands, with software using BERT for query parsing and transformers for generation, aligning with music BPM. Micro-operations sequence granular actions, software coordinating with RL for efficiency. Precision tracking monitors 100 points per body part using Lie group models for transformation invariance, software applying convolutional layers for equivariant features. Natural language interfaces parse prompts to invoke modules, generating text, dance, or music via knowledge graphs and diffusion models, with software ensuring coherence across outputs.

In operation, for a user query like "Create a dance to upbeat music," software extracts style and BPM, generates motion via GANs synchronized to audio waveforms, simulates in Gazebo, and outputs joint trajectories.

## Version-Specific Details

### V1

**Features**: Rigid humanoid frame with 46 motors limited to core joints, basic gear amplification for torque.
**Operational Mechanism**: Motors activate via GPIO pulses, gears amplify rotation for joint displacement. Software computes simple RL actions for locomotion, coordinating without segmentation.
**Advantages**: Minimal components reduce complexity, suitable for basic simulations.
**Disadvantages**: Lacks flexibility in extremities and waist, limiting advanced tasks.
**Defects**: Prone to rigidity-induced vibrations in uneven scenarios.
**Improvements**: Establishes baseline actuation for subsequent enhancements.
**Future Prospects**: Incorporate segmentation to improve adaptability.

### V2

**Features**: 152 motors with five-segment shrimp-shell waist for enhanced dexterity, including fingers and toes.
**Operational Mechanism**: Motors drive segments individually, software uses RL to sequence multi-DOF movements, coordinating via APIs for grasping or stepping.
**Advantages**: Greater range for creative applications like dance.
**Disadvantages**: Increased motor count raises power consumption.
**Defects**: Potential synchronization issues in high-speed operations.
**Improvements**: Adds waist flexibility over V1's rigidity.
**Future Prospects**: Extend segmentation universally for full-body agility.

### V3

**Features**: 141 motors with tendon-driven shrimp-shell joints across all articulations, 360-degree waist turntable for rotation.
**Operational Mechanism**: Dual motors per joint pull tendons for flexion/extension, software adjusts tensions dynamically via feedback, enabling full rotation through dedicated motor.
**Advantages**: Improved maneuverability in dynamic simulations.
**Disadvantages**: Tendon complexity may introduce wear in long-term models.
**Defects**: Antagonistic control can lead to minor backlash.
**Improvements**: Universal segmentation and turntable over V2.
**Future Prospects**: Streamline to single-motor for efficiency.

### V4

**Features**: 71 motors with single-motor tendon-spring joints, optimized for cost.
**Operational Mechanism**: Single motor tensions tendons, springs return positions, software optimizes dynamic coefficients for precision, coordinating reduced DOFs via quantized RL.
**Advantages**: Lower resource needs for broader accessibility.
**Disadvantages**: Spring backlash slightly affects ultra-precision.
**Defects**: Reduced redundancy in fault scenarios.
**Improvements**: Simplifies V3's dual setup with passive springs.
**Future Prospects**: Explore hybrid materials for zero-backlash.

## Implementation Considerations

The backend leverages Python with PyTorch for RL and generative models, Arduino IDE for V4's embedded control. Scalability requires GPUs for V2 and V3; limitations include latency in tendon feedback. Ethical focus ensures secure simulated data handling.

## Conclusion and Future Work

The Heracles system evolves progressively, integrating actuation, perception, and generation for versatile simulations. Future work may enhance with multimodal inputs and energy-efficient designs.

## Document Data

- Author: Carson Wu
- Document Identification Code: 20251007_01
- The development timeline: 2016 - Present
